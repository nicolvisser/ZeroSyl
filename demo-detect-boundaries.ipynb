{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79842723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tgt\n",
    "import torch\n",
    "import torchaudio\n",
    "from pydub import AudioSegment\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "from zerosyl.wavlm import WavLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ac0b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the waveform and alignment paths\n",
    "\n",
    "waveform_dir = Path(\"data/waveforms/LibriSpeech/dev-clean\")\n",
    "alignment_dir = Path(\"data/alignments/LibriSpeech/dev-clean\")\n",
    "\n",
    "waveform_paths = {p.stem: p for p in waveform_dir.rglob(\"*.flac\")}\n",
    "alignment_paths = {p.stem: p for p in alignment_dir.rglob(\"*.TextGrid\")}\n",
    "\n",
    "common_stems = sorted(waveform_paths.keys() & alignment_paths.keys())\n",
    "waveform_paths = [waveform_paths[s] for s in common_stems]\n",
    "alignment_paths = [alignment_paths[s] for s in common_stems]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf948de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a random example\n",
    "\n",
    "index = np.random.randint(len(waveform_paths))\n",
    "waveform_path = waveform_paths[index]\n",
    "alignment_path = alignment_paths[index]\n",
    "\n",
    "tg = tgt.read_textgrid(alignment_path, include_empty_intervals=False)\n",
    "words = [interval.text for interval in tg.get_tier_by_name(\"words\")]\n",
    "print(f\"Processing {waveform_path.name}, {\" \".join(words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882ccf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for plotting and listening\n",
    "\n",
    "def listen_to_segmentation(waveform_path, peaks):\n",
    "    audio = AudioSegment.from_file(waveform_path)\n",
    "    segments = []\n",
    "\n",
    "    for i in range(len(peaks) - 1):\n",
    "        start_ms = int(peaks[i] * 20)  \n",
    "        end_ms = int(peaks[i + 1] * 20)\n",
    "        segment = audio[start_ms:end_ms]\n",
    "        segments.append(segment)\n",
    "    combined = AudioSegment.silent(duration=0)\n",
    "    for segment in segments:\n",
    "        combined += segment + AudioSegment.silent(duration=500)\n",
    "    return ipd.Audio(combined.export(format=\"wav\").read(), rate=16000)\n",
    "\n",
    "def get_frame_num(time_sec):\n",
    "    return np.floor(np.round((time_sec / 20 * 1000), 1) + 0.5).astype(np.int32) \n",
    "\n",
    "def plot_segmentation(\n",
    "    waveform, \n",
    "    tg: tgt.TextGrid,\n",
    "    peaks=None,\n",
    "    norms=None,\n",
    "    norms_smooth=None,\n",
    "    ax=None,\n",
    "    title=None\n",
    "):\n",
    "    tMel = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=16000,\n",
    "        n_fft=1024,\n",
    "        win_length=400,\n",
    "        hop_length=320,\n",
    "        f_min=0,\n",
    "        f_max=8000,\n",
    "        n_mels=128,\n",
    "        center=True,\n",
    "    )\n",
    "    n_mels = tMel.n_mels\n",
    "    tDB = torchaudio.transforms.AmplitudeToDB(top_db=80)\n",
    "    melspec = tDB(tMel(waveform.cpu()))  \n",
    "    mels = melspec[0].numpy()\n",
    "    \n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 3))\n",
    "    ax.imshow(mels, aspect=\"auto\", origin=\"lower\")\n",
    "    ax.set_ylim(0, mels.shape[0])\n",
    "\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    def x_coords(n):\n",
    "        return [i + 0.5 for i in range(n)]\n",
    "\n",
    "    def sec_to_frame(s):  \n",
    "        return int(np.round(s * 50))\n",
    "    \n",
    "    if norms is not None:\n",
    "        ax.plot(x_coords(len(norms)), 10 * np.asarray(norms) + 64, color=\"w\", linewidth=1.0, alpha=0.9)\n",
    "    if norms_smooth is not None:\n",
    "        ax.plot(x_coords(len(norms_smooth)), 10 * np.asarray(norms_smooth) + 64, color=\"r\", linewidth=1.0)\n",
    "\n",
    "    if peaks is not None:\n",
    "        peaks = np.asarray(peaks, dtype=int)\n",
    "        if norms_smooth is not None:\n",
    "            valid = peaks[(peaks >= 0) & (peaks < len(norms_smooth))]\n",
    "            yvals = 10 * np.asarray(norms_smooth)[valid] + 64\n",
    "            ax.plot([p + 0.5 for p in valid], yvals, \"r*\", markersize=10)\n",
    "        elif norms is not None:\n",
    "            valid = peaks[(peaks >= 0) & (peaks < len(norms))]\n",
    "            yvals = 10 * np.asarray(norms)[valid] + 64\n",
    "            ax.plot([p + 0.5 for p in valid], yvals, \"r*\", markersize=10)\n",
    "        else:\n",
    "            for p in peaks:\n",
    "                ax.axvline(p, color=\"r\", linestyle=\"-.\", linewidth=0.8)\n",
    "        \n",
    "    for iv in tg.get_tier_by_name(\"syllables\"):\n",
    "        start_f = sec_to_frame(float(iv.start_time))\n",
    "        end_f   = sec_to_frame(float(iv.end_time))\n",
    "        ax.axvline(start_f, color=\"w\", linestyle=\"--\", alpha=0.5, linewidth=0.8)\n",
    "        ax.axvline(end_f,   color=\"w\", linestyle=\"--\", alpha=0.5, linewidth=0.8)\n",
    "        ax.text((start_f + end_f) / 2.0, n_mels - 18,\n",
    "                getattr(iv, \"text\", \"\"), color=\"w\", fontsize=8,\n",
    "                ha=\"center\", va=\"center\", rotation=90)\n",
    "    \n",
    "    for iv in tg.get_tier_by_name(\"syllables\"):\n",
    "        start_f = sec_to_frame(float(iv.start_time))\n",
    "        end_f   = sec_to_frame(float(iv.end_time))\n",
    "        ax.axvline(start_f, color=\"w\", linestyle=\"-\", alpha=1.0, linewidth=0.9)\n",
    "        ax.axvline(end_f,   color=\"w\", linestyle=\"-\", alpha=1.0, linewidth=0.9)\n",
    "    \n",
    "    ax.set_xlabel(\"Frame\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57d6080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment with prominence based peak detection on the norms\n",
    "\n",
    "def norm_promseg(feat, window_size, prominence):\n",
    "    norm = np.linalg.norm(feat, axis=1)\n",
    "    mu, std = np.mean(norm), np.std(norm)\n",
    "    norm_z = (norm - mu) / std\n",
    "    kernel = np.ones(window_size) / window_size\n",
    "    pad = window_size // 2\n",
    "    norm_smooth = np.convolve(np.pad(norm_z, (pad, pad), mode='edge'), kernel, mode='valid')\n",
    "    peaks, _ = find_peaks(norm_smooth, prominence=prominence)\n",
    "    return norm_z, norm_smooth, peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ab5829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "LAYER = 13\n",
    "WINDOW_SIZE= 3\n",
    "PROMINENCE = 0.45\n",
    "\n",
    "# Load the model\n",
    "wavlm = WavLM.from_remote().cuda()\n",
    "\n",
    "# Load the waveform and preprocess\n",
    "waveform, sr = torchaudio.load(str(waveform_path))\n",
    "if wavlm.cfg.normalize:\n",
    "    waveform = torch.nn.functional.layer_norm(waveform, waveform.shape)\n",
    "waveform = torch.nn.functional.pad(waveform, ((400 - 320) // 2, (400 - 320) // 2))\n",
    "\n",
    "# Extract features\n",
    "with torch.inference_mode():\n",
    "    feat, _ = wavlm.extract_features(waveform.cuda(), output_layer=LAYER)\n",
    "feat = feat.squeeze(0).cpu().numpy()\n",
    "\n",
    "# Segment\n",
    "norms, norms_smooth, peaks = norm_promseg(feat, window_size=WINDOW_SIZE, prominence=PROMINENCE)\n",
    "print(\"Number of peaks detected:\", len(peaks))\n",
    "\n",
    "# Plot\n",
    "plot_segmentation(\n",
    "    waveform, \n",
    "    tg,\n",
    "    peaks=peaks,\n",
    "    norms=norms,\n",
    "    norms_smooth=norms_smooth,\n",
    "    title=f\"WavLM layer {LAYER} with PromNormSeg\"\n",
    ")\n",
    "listen_to_segmentation(waveform_path, peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a9b218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zerosyl-Suft6ghr-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
