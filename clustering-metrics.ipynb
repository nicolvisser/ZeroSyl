{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d93067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tgt\n",
    "import torch\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torchcodec.decoders import AudioDecoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "from zerosyl.model import ZeroSylDiscrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7712f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_dir = Path(\"data/waveforms/LibriSpeech\")\n",
    "alignment_dir = Path(\"data/alignments/LibriSpeech\")\n",
    "\n",
    "waveform_paths = {p.stem: p for p in waveform_dir.glob(\"dev*/**/*.flac\")}\n",
    "alignment_paths = {p.stem: p for p in alignment_dir.glob(\"dev*/**/*.TextGrid\")}\n",
    "\n",
    "assert len(waveform_paths) > 0\n",
    "assert len(alignment_paths) > 0\n",
    "common_stems = waveform_paths.keys() & alignment_paths.keys()\n",
    "assert len(common_stems) > 0\n",
    "waveform_paths = [waveform_paths[stem] for stem in common_stems]\n",
    "alignment_paths = [alignment_paths[stem] for stem in common_stems]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d20bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to ensure you are working with all utterances from dev-clean and dev-other sets\n",
    "assert len(common_stems) == 5567"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e107f0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolvisser/.cache/pypoetry/virtualenvs/zerosyl-Suft6ghr-py3.12/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "model = ZeroSylDiscrete.from_pretrained_checkpoint(\"checkpoints/WavLM-Large.pt\", \"checkpoints/km10000-centroids-v020.pt\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f624366b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data: 100%|██████████| 5567/5567 [03:49<00:00, 24.25it/s]\n"
     ]
    }
   ],
   "source": [
    "all_syllables = []\n",
    "all_tokens = []\n",
    "for waveform_path, alignment_path in zip(tqdm(waveform_paths, desc=\"loading data\"), alignment_paths):\n",
    "    # extract ground truth syllables from the alignment file\n",
    "    tg = tgt.read_textgrid(alignment_path, include_empty_intervals=True)\n",
    "    tier = tg.get_tier_by_name(\"syllables\")\n",
    "    timesteps = np.arange(0.5/100, tg.end_time, 1/100) # 100 Hz\n",
    "    syllables = [tier.get_annotations_by_time(t)[0].text for t in timesteps]\n",
    "    syllables = [(\"SIL\" if s == \"\" else s) for s in syllables]\n",
    "\n",
    "    # extract tokens from the speech\n",
    "    decoder = AudioDecoder(waveform_path, sample_rate=16000, num_channels=1)\n",
    "    audio = decoder.get_all_samples()\n",
    "    tokens, starts, ends = model.tokenize(audio.data.cuda())\n",
    "    tokens_duped = torch.repeat_interleave(tokens, ends-starts, dim=0) # 50Hz\n",
    "    tokens_duped = torch.repeat_interleave(tokens_duped, 2) # 100Hz\n",
    "    tokens_duped = tokens_duped.cpu().numpy()\n",
    "\n",
    "    assert abs(len(syllables) - len(tokens_duped)) <= 3\n",
    "    minlen = min(len(syllables), len(tokens_duped))\n",
    "    syllables = syllables[:minlen]\n",
    "    tokens_duped = tokens_duped[:minlen]\n",
    "\n",
    "    all_syllables.append(syllables)\n",
    "    all_tokens.append(tokens_duped)\n",
    "\n",
    "all_syllables = np.concatenate(all_syllables, axis=0)\n",
    "all_tokens = np.concatenate(all_tokens, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "642d16b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "syllable_label_encoder = LabelEncoder()\n",
    "all_syllable_ids = syllable_label_encoder.fit_transform(all_syllables)\n",
    "\n",
    "token_label_encoder = LabelEncoder()\n",
    "all_token_ids = token_label_encoder.fit_transform(all_tokens)\n",
    "\n",
    "n_syllables = len(syllable_label_encoder.classes_)\n",
    "n_tokens = len(token_label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e701b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_counts = contingency_matrix(all_syllable_ids, all_token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84a7b411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joint probabilities\n",
    "p_yz = joint_counts / joint_counts.sum() + 1e-10 # (I,J)\n",
    "I, J = p_yz.shape\n",
    "\n",
    "# marginal probabilities\n",
    "p_y = np.sum(p_yz, axis=1) # (I,)\n",
    "p_z = np.sum(p_yz, axis=0) # (J,)\n",
    "\n",
    "# most likely target label\n",
    "z_star = np.argmax(p_yz, axis=1) # (I,)\n",
    "# most likely syllable label\n",
    "y_star = np.argmax(p_yz, axis=0) # (J,)\n",
    "\n",
    "# conditional probabilities\n",
    "p_y_given_z = p_yz / p_z[None,:] # (I,J)\n",
    "p_z_given_y = p_yz / p_y[:, None] # (I,J)\n",
    "\n",
    "# syllable purity\n",
    "sp = np.sum(p_y_given_z[y_star,np.arange(J)] * p_z)\n",
    "\n",
    "# cluster purity\n",
    "cp = np.sum(p_z_given_y[np.arange(I),z_star] * p_y)\n",
    "\n",
    "# syllable-normalized mutual information\n",
    "snmi = - (p_yz * np.log(p_yz /  p_y[:, None] / p_z[None,:])).sum() / (p_y * np.log(p_y)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b7f0647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syllable purity:                        0.6693\n",
      "Cluster purity:                         0.1859\n",
      "Syllable-normalized mutial information: 0.7896\n"
     ]
    }
   ],
   "source": [
    "print(f\"Syllable purity:                        {sp.item():.4f}\")\n",
    "print(f\"Cluster purity:                         {cp.item():.4f}\")\n",
    "print(f\"Syllable-normalized mutial information: {snmi.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zerosyl-Suft6ghr-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
