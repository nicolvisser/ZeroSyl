{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d97f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tgt\n",
    "from IPython.display import Audio, display\n",
    "from torchaudio.transforms import AmplitudeToDB, MelSpectrogram\n",
    "from torchcodec.decoders import AudioDecoder\n",
    "\n",
    "from zerosyl.encoder import ZeroSylDiscrete, ZeroSylCollapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0a6ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the waveform and alignment paths\n",
    "\n",
    "waveform_dir = Path(\"data/waveforms/LibriSpeech/dev-clean\")\n",
    "alignment_dir = Path(\"data/alignments/LibriSpeech/dev-clean\")\n",
    "\n",
    "waveform_paths = {p.stem: p for p in waveform_dir.rglob(\"*.flac\")}\n",
    "alignment_paths = {p.stem: p for p in alignment_dir.rglob(\"*.TextGrid\")}\n",
    "\n",
    "common_stems = sorted(waveform_paths.keys() & alignment_paths.keys())\n",
    "waveform_paths = [waveform_paths[s] for s in common_stems]\n",
    "alignment_paths = [alignment_paths[s] for s in common_stems]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9968080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a random example\n",
    "\n",
    "index = np.random.randint(len(waveform_paths))\n",
    "waveform_path = waveform_paths[index]\n",
    "alignment_path = alignment_paths[index]\n",
    "\n",
    "tg = tgt.read_textgrid(alignment_path, include_empty_intervals=False)\n",
    "words = [interval.text for interval in tg.get_tier_by_name(\"words\")]\n",
    "print(f\"Processing {waveform_path.name}, {\" \".join(words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ce80db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for plotting\n",
    "\n",
    "def plot_boundaries(melspec, textgrid, tokens, starts, ends, model):\n",
    "    plt.figure(figsize=(12, 6), constrained_layout=True)\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.imshow(melspec, aspect=\"auto\", origin=\"lower\")\n",
    "    xticks = []\n",
    "    xtickslabels = []\n",
    "    for interval in textgrid.get_tier_by_name(\"syllables\"):\n",
    "        x1 = interval.start_time * 50\n",
    "        x2 = interval.end_time * 50\n",
    "        xticks.append((x1 + x2) / 2)\n",
    "        xtickslabels.append(interval.text)\n",
    "        plt.axvline(x1, color=\"white\")\n",
    "        plt.axvline(x2, color=\"white\")\n",
    "    plt.xticks(xticks, xtickslabels, rotation=90)\n",
    "    plt.gca().get_yaxis().set_visible(False)\n",
    "    plt.gca().xaxis.set_ticks_position(\"top\")\n",
    "    plt.gca().xaxis.set_label_position(\"top\")\n",
    "    plt.title(\"Syllables from forced alignments\")\n",
    "    plt.xlim(0, textgrid.end_time * 50)\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.imshow(melspec, aspect=\"auto\", origin=\"lower\")\n",
    "    xticks = []\n",
    "    xtickslabels = []\n",
    "    for token, start, end in zip(tokens, starts, ends):\n",
    "        x1 = start.item()\n",
    "        x2 = end.item()\n",
    "        xticks.append((x1 + x2) / 2)\n",
    "        xtickslabels.append(str(token.item()))\n",
    "        plt.axvline(x1, color=\"white\")\n",
    "        plt.axvline(x2, color=\"white\")\n",
    "    plt.xticks(xticks, xtickslabels, rotation=90)\n",
    "    plt.gca().get_yaxis().set_visible(False)\n",
    "    plt.title(f\"{model} boundaries and tokens\")\n",
    "    plt.xlim(0, textgrid.end_time * 50)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84fbe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "textgrid = tgt.read_textgrid(alignment_path, include_empty_intervals=False)\n",
    "\n",
    "decoder = AudioDecoder(waveform_path, sample_rate=16000, num_channels=1)\n",
    "audio = decoder.get_all_samples()\n",
    "wav = audio.data.cuda()\n",
    "\n",
    "tMelSpectrogram = MelSpectrogram(16000, 1024, 400, 320, n_mels=100)\n",
    "tAmplitudeToDB = AmplitudeToDB(top_db=80)\n",
    "\n",
    "melspec = tAmplitudeToDB(tMelSpectrogram(audio.data))[0]\n",
    "\n",
    "display(Audio(waveform_path))\n",
    "\n",
    "transcription = \" \".join([interval.text for interval in textgrid.get_tier_by_name(\"words\")])\n",
    "print(f\"Transcription: {transcription}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128985f5",
   "metadata": {},
   "source": [
    "## Model without collapsing silences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37891b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"model\" not in locals():\n",
    "    model = ZeroSylDiscrete.from_remote().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57c13eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "starts, ends, ids = model.encode(wav)\n",
    "plot_boundaries(melspec, textgrid, ids, starts, ends, model=\"ZeroSylDiscrete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79df18d",
   "metadata": {},
   "source": [
    "## Model with silences collapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4e5665",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"model_with_collapsing\" not in locals():\n",
    "    model_with_collapsing = ZeroSylCollapsed.from_remote().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e889343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "starts, ends, ids = model_with_collapsing.encode(wav)\n",
    "plot_boundaries(melspec, textgrid, ids, starts, ends, model=\"ZeroSylCollapse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39842a04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zerosyl-Suft6ghr-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
